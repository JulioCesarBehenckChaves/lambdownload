import boto3
import json
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime


def check_aws_credentials():
    """Verifica se as credenciais AWS estÃ£o configuradas"""
    try:
        sts = boto3.client('sts')
        identity = sts.get_caller_identity()
        print(f"âœ… AWS configurado para conta: {identity['Account']}")
        print(f"âœ… UsuÃ¡rio/Role: {identity['Arn']}")
        return True
    except Exception as e:
        print(f"âŒ Erro nas credenciais AWS: {str(e)}")
        print("ğŸ’¡ Configure com: aws configure")
        return False


def test_lambda_function_simple(lambda_client, function_name):
    """Testa a funÃ§Ã£o Lambda fazendo uma invocaÃ§Ã£o de teste simples"""
    try:
        print(f"ğŸ” Testando funÃ§Ã£o Lambda: {function_name}")

        # Fazer uma invocaÃ§Ã£o de teste simples (sem URL para gerar erro esperado)
        response = lambda_client.invoke(
            FunctionName=function_name,
            InvocationType='RequestResponse',
            Payload=json.dumps({})
        )

        # Se chegou atÃ© aqui, a funÃ§Ã£o existe e Ã© acessÃ­vel
        print(f"âœ… FunÃ§Ã£o Lambda acessÃ­vel: {function_name}")

        # Verificar se foi erro de parÃ¢metro obrigatÃ³rio (esperado)
        result = json.loads(response['Payload'].read())
        if result['statusCode'] == 400:  # Erro esperado para falta de URL
            print(f"âœ… FunÃ§Ã£o respondeu corretamente ao teste")
            return True
        else:
            print(f"âœ… FunÃ§Ã£o executou com sucesso")
            return True

    except Exception as e:
        error_str = str(e)
        if "does not exist" in error_str or "Function not found" in error_str:
            print(f"âŒ FunÃ§Ã£o Lambda nÃ£o encontrada: {function_name}")
        elif "AccessDenied" in error_str:
            print(f"âŒ Sem permissÃ£o para acessar funÃ§Ã£o: {function_name}")
        else:
            print(f"âŒ Erro ao testar funÃ§Ã£o Lambda: {error_str}")
        return False


def invoke_lambda_for_file(lambda_client, function_name, file_config, index, total):
    """Invoca a Lambda para um arquivo especÃ­fico"""
    try:
        filename = file_config['filename']
        url = file_config['url']
        print(f"[{index}/{total}] ğŸ”„ Iniciando: {filename}")
        start_time = time.time()

        payload = {
            'url': url,
            'filename': filename
        }
        
        # Adicionar bucket e prefix se fornecidos
        if 'bucket' in file_config:
            payload['bucket'] = file_config['bucket']
        if 'prefix' in file_config:
            payload['prefix'] = file_config['prefix']

        response = lambda_client.invoke(
            FunctionName=function_name,
            InvocationType='RequestResponse',
            Payload=json.dumps(payload)
        )

        result = json.loads(response['Payload'].read())
        execution_time = time.time() - start_time

        if result['statusCode'] == 200:
            body = json.loads(result['body'])
            if body.get('status') == 'skipped':
                print(f"[{index}/{total}] â­ï¸  {filename} - JÃ¡ existe no S3 ({execution_time:.1f}s)")
                return {'filename': filename, 'status': 'skipped', 'result': body, 'execution_time': execution_time}
            else:
                stats = body.get('stats', {})
                size_mb = stats.get('size_mb', 0)
                transfer_time = stats.get('total_time_seconds', 0)
                print(
                    f"[{index}/{total}] âœ… {filename} - {size_mb}MB em {transfer_time:.1f}s (total: {execution_time:.1f}s)")
                return {'filename': filename, 'status': 'success', 'result': body, 'execution_time': execution_time}
        else:
            print(f"[{index}/{total}] âŒ {filename} - Erro Lambda: {result}")
            return {'filename': filename, 'status': 'error', 'result': result, 'execution_time': execution_time}

    except Exception as e:
        execution_time = time.time() - start_time if 'start_time' in locals() else 0
        print(f"[{index}/{total}] ğŸ’¥ {filename} - ExceÃ§Ã£o: {str(e)}")
        return {'filename': filename, 'status': 'exception', 'error': str(e), 'execution_time': execution_time}


def save_results_to_file(results, filename="batch_results.json"):
    """Salva resultados em arquivo JSON"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'results': results
            }, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ Resultados salvos em: {filename}")
    except Exception as e:
        print(f"âŒ Erro ao salvar resultados: {str(e)}")


def process_files_batch():
    """Processa lista de arquivos em lote"""

    # ==========================================
    # CONFIGURAÃ‡Ã•ES - AJUSTE AQUI
    # ==========================================
    function_name = 'lambdownload-function'  # Nome da sua funÃ§Ã£o Lambda
    max_concurrent = 2  # ExecuÃ§Ãµes simultÃ¢neas
    base_url = 'https://example.com/path/'  # URL base dos arquivos
    bucket_name = 'meu-bucket-dados'  # Bucket S3 de destino
    s3_prefix = 'dados-fluxo/'  # Prefixo/pasta no S3

    # LISTA DE ARQUIVOS - COLOQUE SEUS ARQUIVOS AQUI
    filenames = [
        "Dados_Fluxo_Parte_10.zip",
        "Dados_Fluxo_Parte_100.zip",
        "Dados_Fluxo_Parte_101.zip",
        "Dados_Fluxo_Parte_102.zip",
        "Dados_Fluxo_Parte_103.zip"
        # Adicione mais arquivos conforme necessÃ¡rio
    ]

    # Construir lista de configuraÃ§Ãµes de arquivos
    files_to_download = []
    for filename in filenames:
        files_to_download.append({
            'filename': filename,
            'url': f"{base_url}{filename}",
            'bucket': bucket_name,
            'prefix': s3_prefix
        })

    # ==========================================
    # EXECUÃ‡ÃƒO
    # ==========================================

    print(f"ğŸš€ Iniciando processamento em lote")
    print(f"ğŸ“ ConfiguraÃ§Ãµes:")
    print(f"   - FunÃ§Ã£o Lambda: {function_name}")
    print(f"   - Bucket S3: {bucket_name}")
    print(f"   - Prefixo S3: {s3_prefix}")
    print(f"   - URL base: {base_url}")
    print(f"   - Total de arquivos: {len(files_to_download)}")
    print(f"   - ExecuÃ§Ãµes simultÃ¢neas: {max_concurrent}")
    print()

    # Verificar credenciais AWS
    if not check_aws_credentials():
        return

    # Inicializar cliente Lambda
    try:
        lambda_client = boto3.client('lambda')
        print(f"âœ… Cliente Lambda inicializado")
    except Exception as e:
        print(f"âŒ Erro ao inicializar cliente Lambda: {str(e)}")
        return

    # Testar funÃ§Ã£o Lambda
    if not test_lambda_function_simple(lambda_client, function_name):
        print(f"âŒ Abortando execuÃ§Ã£o devido a problemas com a funÃ§Ã£o Lambda")
        return

    print()
    print(f"ğŸ“ˆ Iniciando processamento de {len(files_to_download)} arquivos...")
    print()

    # Processar arquivos com ThreadPoolExecutor
    results = []
    start_time = time.time()

    with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
        # Submeter todas as tarefas
        future_to_file = {
            executor.submit(
                invoke_lambda_for_file,
                lambda_client,
                function_name,
                file_config,
                i + 1,
                len(files_to_download)
            ): file_config for i, file_config in enumerate(files_to_download)
        }

        # Coletar resultados conforme completam
        for future in as_completed(future_to_file):
            file_config = future_to_file[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as exc:
                filename = file_config['filename']
                print(f"ğŸ’¥ {filename} - ExceÃ§Ã£o na thread: {exc}")
                results.append({
                    'filename': filename,
                    'status': 'thread_exception',
                    'error': str(exc),
                    'execution_time': 0
                })

    total_time = time.time() - start_time

    # ==========================================
    # RELATÃ“RIO FINAL
    # ==========================================
    print()
    print("=" * 60)
    print("ğŸ“ˆ RELATÃ“RIO FINAL")
    print("=" * 60)

    # Contar resultados por status
    success_count = len([r for r in results if r['status'] == 'success'])
    skipped_count = len([r for r in results if r['status'] == 'skipped'])
    error_count = len([r for r in results if r['status'] in ['error', 'exception', 'thread_exception']])

    print(f"ğŸ“ Total de arquivos: {len(results)}")
    print(f"âœ… Sucessos: {success_count}")
    print(f"â­ï¸ Ignorados (jÃ¡ existem): {skipped_count}")
    print(f"âŒ Erros: {error_count}")
    print(f"â±ï¸ Tempo total: {total_time:.1f}s")
    print()

    # Mostrar estatÃ­sticas de transferÃªncia
    successful_results = [r for r in results if r['status'] == 'success' and 'result' in r]
    if successful_results:
        total_mb = sum([r['result'].get('stats', {}).get('size_mb', 0) for r in successful_results])
        avg_speed = total_mb / total_time if total_time > 0 else 0
        print(f"ğŸ“ˆ EstatÃ­sticas de transferÃªncia:")
        print(f"   - Total transferido: {total_mb:.1f} MB")
        print(f"   - Velocidade mÃ©dia: {avg_speed:.1f} MB/s")
        print()

    # Mostrar erros se houver
    if error_count > 0:
        print("âŒ ERROS ENCONTRADOS:")
        for result in results:
            if result['status'] in ['error', 'exception', 'thread_exception']:
                filename = result['filename']
                error = result.get('error', result.get('result', 'Erro desconhecido'))
                print(f"   - {filename}: {error}")
        print()

    # Salvar resultados em arquivo
    save_results_to_file(results)

    print("ğŸ‰ Processamento concluÃ­do!")


if __name__ == "__main__":
    process_files_batch()92.zip",
        "Dados_Fluxo_Parte_93.zip",
        "Dados_Fluxo_Parte_94.zip",
        "Dados_Fluxo_Parte_95.zip",
        "Dados_Fluxo_Parte_96.zip",
        "Dados_Fluxo_Parte_97.zip",
        "Dados_Fluxo_Parte_98.zip",
        "Dados_Fluxo_Parte_99.zip",
        "Tabela_Locais.txt"
        # ... adicione todos os arquivos aqui

        # Adicione todos os seus arquivos aqui
    ]

    print("ğŸš€ AWS FTP to S3 Batch Processor")
    print("=" * 60)
    print(f"ğŸ“‹ FunÃ§Ã£o Lambda: {function_name}")
    print(f"ğŸ“ Total de arquivos: {len(files_to_download)}")
    print(f"ğŸ”„ ConcorrÃªncia mÃ¡xima: {max_concurrent}")
    print(f"â° Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # Verificar credenciais AWS
    if not check_aws_credentials():
        return None

    # Inicializar cliente Lambda
    try:
        lambda_client = boto3.client('lambda')
        print("âœ… Cliente Lambda inicializado")
    except Exception as e:
        print(f"âŒ Erro ao inicializar cliente Lambda: {str(e)}")
        return None

    # Testar funÃ§Ã£o Lambda (sem GetFunction)
    if not test_lambda_function_simple(lambda_client, function_name):
        print("âš ï¸  Continuando mesmo com erro no teste...")
        # NÃ£o retornar None aqui, continuar tentando

    print("-" * 60)

    results = []
    start_time = time.time()

    # Processar arquivos com concorrÃªncia limitada
    with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
        # Submeter todas as tarefas
        future_to_info = {
            executor.submit(invoke_lambda_for_file, lambda_client, function_name, filename, i + 1,
                            len(files_to_download)):
                {'filename': filename, 'index': i + 1}
            for i, filename in enumerate(files_to_download)
        }

        # Processar resultados conforme completam
        completed = 0
        for future in as_completed(future_to_info):
            result = future.result()
            results.append(result)
            completed += 1

            # Mostrar progresso
            progress = (completed / len(files_to_download)) * 100
            print(f"ğŸ“Š Progresso: {completed}/{len(files_to_download)} ({progress:.1f}%)")

    # RelatÃ³rio final
    total_time = time.time() - start_time
    successful = len([r for r in results if r['status'] == 'success'])
    skipped = len([r for r in results if r['status'] == 'skipped'])
    failed = len([r for r in results if r['status'] in ['error', 'exception']])

    print("\n" + "=" * 60)
    print("ğŸ“Š RELATÃ“RIO FINAL")
    print("=" * 60)
    print(f"âœ… Sucessos: {successful}")
    print(f"â­ï¸  Pulados (jÃ¡ existiam): {skipped}")
    print(f"âŒ Falhas: {failed}")
    print(f"ğŸ“ Total: {len(files_to_download)}")
    print(f"â±ï¸  Tempo total: {total_time:.2f}s")
    if len(files_to_download) > 0:
        print(f"âš¡ MÃ©dia por arquivo: {total_time / len(files_to_download):.2f}s")
    print("=" * 60)

    # Mostrar falhas detalhadas
    failures = [r for r in results if r['status'] in ['error', 'exception']]
    if failures:
        print("\nâŒ ARQUIVOS COM FALHA:")
        for failure in failures:
            error_msg = failure.get('error', failure.get('result', 'Erro desconhecido'))
            print(f"   - {failure['filename']}: {error_msg}")

    # Salvar resultados
    save_results_to_file(results)

    return results


def main():
    """FunÃ§Ã£o principal"""
    try:
        results = process_files_batch()
        if results:
            print(f"\nğŸ‰ Processamento concluÃ­do! Verifique o arquivo batch_results.json")
        else:
            print(f"\nğŸ’¥ Processamento falhou na configuraÃ§Ã£o inicial")
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  Processamento interrompido pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nğŸ’¥ Erro inesperado: {str(e)}")


if __name__ == "__main__":
    main()
